{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fraud Detection\n",
    "\n",
    "## Task\n",
    "\n",
    "Build a logistic regression model using Scikit-learn to predict fraudulent transactions by training it on [Credit Card Fraud Detection](https://www.kaggle.com/c/ieee-fraud-detection/data) dataset from Kaggle. Before you train the model, create at least 1 visualization of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler # Scaling by standardisation\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the Dataset / Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>127695.0</td>\n",
       "      <td>-1.180302</td>\n",
       "      <td>0.997052</td>\n",
       "      <td>-1.141980</td>\n",
       "      <td>1.122934</td>\n",
       "      <td>0.870430</td>\n",
       "      <td>0.496341</td>\n",
       "      <td>2.626909</td>\n",
       "      <td>-0.275357</td>\n",
       "      <td>-1.251222</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.116098</td>\n",
       "      <td>-0.213810</td>\n",
       "      <td>-0.495616</td>\n",
       "      <td>-0.008486</td>\n",
       "      <td>1.185834</td>\n",
       "      <td>-0.207036</td>\n",
       "      <td>0.126568</td>\n",
       "      <td>-0.016534</td>\n",
       "      <td>362.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>74522.0</td>\n",
       "      <td>-0.491090</td>\n",
       "      <td>0.736967</td>\n",
       "      <td>1.121518</td>\n",
       "      <td>1.855768</td>\n",
       "      <td>2.192105</td>\n",
       "      <td>4.720293</td>\n",
       "      <td>-0.499471</td>\n",
       "      <td>1.195404</td>\n",
       "      <td>-1.064379</td>\n",
       "      <td>...</td>\n",
       "      <td>0.093564</td>\n",
       "      <td>0.267335</td>\n",
       "      <td>-0.344519</td>\n",
       "      <td>1.041548</td>\n",
       "      <td>0.398812</td>\n",
       "      <td>0.448862</td>\n",
       "      <td>0.111847</td>\n",
       "      <td>0.087620</td>\n",
       "      <td>18.15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>141751.0</td>\n",
       "      <td>-1.081088</td>\n",
       "      <td>-0.891385</td>\n",
       "      <td>1.263885</td>\n",
       "      <td>-0.395564</td>\n",
       "      <td>1.579365</td>\n",
       "      <td>-1.016444</td>\n",
       "      <td>-0.654525</td>\n",
       "      <td>0.249166</td>\n",
       "      <td>0.485191</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003331</td>\n",
       "      <td>-0.447941</td>\n",
       "      <td>0.267298</td>\n",
       "      <td>0.545437</td>\n",
       "      <td>-0.103051</td>\n",
       "      <td>-0.631727</td>\n",
       "      <td>-0.021950</td>\n",
       "      <td>0.028339</td>\n",
       "      <td>1.18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>131485.0</td>\n",
       "      <td>2.057686</td>\n",
       "      <td>-0.038430</td>\n",
       "      <td>-1.058048</td>\n",
       "      <td>0.417849</td>\n",
       "      <td>-0.127807</td>\n",
       "      <td>-1.212282</td>\n",
       "      <td>0.204981</td>\n",
       "      <td>-0.350565</td>\n",
       "      <td>0.502264</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.284453</td>\n",
       "      <td>-0.677820</td>\n",
       "      <td>0.336365</td>\n",
       "      <td>0.053365</td>\n",
       "      <td>-0.291787</td>\n",
       "      <td>0.194302</td>\n",
       "      <td>-0.069472</td>\n",
       "      <td>-0.058925</td>\n",
       "      <td>3.96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>38305.0</td>\n",
       "      <td>0.658722</td>\n",
       "      <td>-2.234003</td>\n",
       "      <td>1.721964</td>\n",
       "      <td>0.101310</td>\n",
       "      <td>-2.625252</td>\n",
       "      <td>0.696838</td>\n",
       "      <td>-1.609055</td>\n",
       "      <td>0.428602</td>\n",
       "      <td>0.870870</td>\n",
       "      <td>...</td>\n",
       "      <td>0.496141</td>\n",
       "      <td>1.149756</td>\n",
       "      <td>-0.402166</td>\n",
       "      <td>0.628406</td>\n",
       "      <td>0.346473</td>\n",
       "      <td>0.039347</td>\n",
       "      <td>0.042984</td>\n",
       "      <td>0.071146</td>\n",
       "      <td>298.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Time        V1        V2        V3        V4        V5        V6  \\\n",
       "0  127695.0 -1.180302  0.997052 -1.141980  1.122934  0.870430  0.496341   \n",
       "1   74522.0 -0.491090  0.736967  1.121518  1.855768  2.192105  4.720293   \n",
       "2  141751.0 -1.081088 -0.891385  1.263885 -0.395564  1.579365 -1.016444   \n",
       "3  131485.0  2.057686 -0.038430 -1.058048  0.417849 -0.127807 -1.212282   \n",
       "4   38305.0  0.658722 -2.234003  1.721964  0.101310 -2.625252  0.696838   \n",
       "\n",
       "         V7        V8        V9  ...       V21       V22       V23       V24  \\\n",
       "0  2.626909 -0.275357 -1.251222  ... -0.116098 -0.213810 -0.495616 -0.008486   \n",
       "1 -0.499471  1.195404 -1.064379  ...  0.093564  0.267335 -0.344519  1.041548   \n",
       "2 -0.654525  0.249166  0.485191  ... -0.003331 -0.447941  0.267298  0.545437   \n",
       "3  0.204981 -0.350565  0.502264  ... -0.284453 -0.677820  0.336365  0.053365   \n",
       "4 -1.609055  0.428602  0.870870  ...  0.496141  1.149756 -0.402166  0.628406   \n",
       "\n",
       "        V25       V26       V27       V28  Amount  Class  \n",
       "0  1.185834 -0.207036  0.126568 -0.016534  362.00      0  \n",
       "1  0.398812  0.448862  0.111847  0.087620   18.15      0  \n",
       "2 -0.103051 -0.631727 -0.021950  0.028339    1.18      0  \n",
       "3 -0.291787  0.194302 -0.069472 -0.058925    3.96      0  \n",
       "4  0.346473  0.039347  0.042984  0.071146  298.00      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('creditcard.csv', low_memory=False)\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check if Any Missing Values in the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      0\n",
       "V1        0\n",
       "V2        0\n",
       "V3        0\n",
       "V4        0\n",
       "V5        0\n",
       "V6        0\n",
       "V7        0\n",
       "V8        0\n",
       "V9        0\n",
       "V10       0\n",
       "V11       0\n",
       "V12       0\n",
       "V13       0\n",
       "V14       0\n",
       "V15       0\n",
       "V16       0\n",
       "V17       0\n",
       "V18       0\n",
       "V19       0\n",
       "V20       0\n",
       "V21       0\n",
       "V22       0\n",
       "V23       0\n",
       "V24       0\n",
       "V25       0\n",
       "V26       0\n",
       "V27       0\n",
       "V28       0\n",
       "Amount    0\n",
       "Class     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No missing values were detected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of non-fraudulent operations: 284315\n",
      "Number of fraudulent operations: 492\n",
      "The average amount of fradulent transactions is 122.21132113821143\n",
      "The maximum amount of fradulent transactions is 2125.87\n"
     ]
    }
   ],
   "source": [
    "fraud = df.loc[df['Class'] == 1]\n",
    "non_fraud = df.loc[df['Class'] == 0]\n",
    "print(f'Number of non-fraudulent operations: {len(non_fraud)}')\n",
    "print(f'Number of fraudulent operations: {len(fraud)}')\n",
    "print(f\"The average amount of fradulent transactions is {fraud['Amount'].mean()}\")\n",
    "print(f\"The maximum amount of fradulent transactions is {fraud['Amount'].max()}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the Amount vs Class distribution\n",
    "plt.scatter(df['Amount'],df['Class'])\n",
    "plt.title('Amount vs Class distribution')\n",
    "plt.xlabel('Amount (currency)')\n",
    "plt.ylabel('Class: (1)-fraud, (0)-legitimate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decide Which Features Are Important\n",
    "\n",
    "In this analysis we will not use the \"Time\" feature. Our matrix \"X\" of independent variables will consist of the features \"V1\" through \"V28\" and also include the \"Amount\" feature. The dependent variable vector \"y\" will consist the values of the \"Class\" column of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, 1:-1].values\n",
    "y = df.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spliting the dataset into the Training set (85%) and Test set (15%)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.15, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_X = StandardScaler()\n",
    "X_train = sc_X.fit_transform(X_train) # Need to fit the object into our feature set, then transform feature set\n",
    "X_test = sc_X.transform(X_test) # Only need to transform, because the object is already fitted (prev. line), otherwise different scales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=0, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting Logistic Regression to the Training set\n",
    "classifier = LogisticRegression(random_state = 0)  # using the same random_state\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the Model On the Testing Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate Performance of the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[42642     5]\n",
      " [   25    50]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of correct predictions: 42692\n",
      "Number of incorrect predictions: 30\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of correct predictions: {cm[0,0] + cm[1,1]}')\n",
    "print(f'Number of incorrect predictions: {cm[0,1] + cm[1,0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very good!\n",
    "The performance score of the model on the Test Set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9992977856841908\n"
     ]
    }
   ],
   "source": [
    "print(classifier.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But if we remember the main purpose of this model - to detect fradulent credit card transactions, we should rather be interested in how well the model can detect fradulent transactions specifically. For that we will use the __recall score__ - the ability of the classifier to find all the positive (fradulent) samples: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "print(recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not a bad number, but in order for the model to be used in production the __recall score__ must be significally improved.\n",
    "\n",
    "Finally the full Classification Report with other performance scores of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     42647\n",
      "           1       0.91      0.67      0.77        75\n",
      "\n",
      "    accuracy                           1.00     42722\n",
      "   macro avg       0.95      0.83      0.88     42722\n",
      "weighted avg       1.00      1.00      1.00     42722\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class_report = classification_report(y_test, y_pred)\n",
    "print(class_report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
